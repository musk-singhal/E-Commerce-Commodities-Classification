{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>bag_of_words.ipynb</font>\n",
    "\n",
    "<br><b>Filename: bag_of_words.ipynb</b> ---> <font color='purple'>defines the implementation pipeline from creating bag of words using proportionate valus from each primary category to computing the word count of each record description in all bags of words.</font>\n",
    "<hr/>\n",
    "This notebook specifies the following functions: ( the sequence of description is same as the sequence of their definition in the notebook cells below )\n",
    "<ol>\n",
    "    <li><b>get_dataframes( df, size ): </b> Given the dataset 'df' as input, the function splits it into train set ( used for creating bag of words ) of number of records = 'size' and test set ( for predicting the categories using the bag of words created ) with each category having proportional number of records in the dataset. For eg: Given 'size' = 0.85, i.e. train set is 85% of the dataset D, each category will have 85% of its total number of records in D, present in the training set. </li>\n",
    "    <li><b>get_bow( df, cat ):</b> Given the train set 'df' and 'cat' as the list of primary categories, this function creates the bag of words by word tokenizing each training set record description and dumping them into the bag corresponding to its category.</li>\n",
    "    <li><b>get_results( bow, test ):</b> Given the set of bags of words 'bow' and the test set 'test', the function returns a list wherein each element represents the fraction of words of the corresponding test set record present in each of the bag of words in 'bow'. For eg: Given B bags of words and T test set records, this function returns a T element list with each element being a list of B fraction values, depicting the amount of words found in that bag of words.</li>\n",
    "    <li><b>predict_categories( bow, test ):</b>Prepare the result dataframe. This function internally calls the get_results() function described previously in order to prepare the resultant dataframe.</li>\n",
    "    <li><b>bow_model( data, cat ):</b>Driver function for the bag of words model. It instantiates a variable to specify the training set size and shuffles the dataset prior to creating the bag of words.</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CELL #1: importing required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import scipy as sp\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CELL #2: defining get_dataframes( df,size )\n",
    "Function description in the top cell\n",
    "<br>This function does the following sequence of operations:\n",
    "<ol>\n",
    "    <li>Obtain the shuffled dataset from the driver function</li>\n",
    "    <li>Display the number of records per category</li>\n",
    "    <li>Retrieve the first N records for each category from the dataset, where <b>N = size * (number of records)</b> & 0.0 <= size <= 1.0. Since the dataset was received pre-shuffled, the chances of obtaining majority od records from the dominating category is not pre-determined.</li>\n",
    "    <li>Populate the training set</li>\n",
    "    <li>Drop the records from the dataset that have been stored as part of training set, to obtain the test set.</li>\n",
    "    <li>Return the train set and test set.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframes(df,size): # ------------------------------------------------------------ STEP-1\n",
    "    \n",
    "    counts = Counter(df.loc[:,'cat'])\n",
    "    #print(len(counts))\n",
    "    #print(\"Original category counts = \",counts) # ----------------------------------------- STEP-2\n",
    "    \n",
    "    # ------------------------------------------------------------ STEP-3 STARTS HERE\n",
    "    for key in counts:\n",
    "        counts[key] = math.floor(size*counts[key])\n",
    "        \n",
    "        if math.floor(size*counts[key]) == 0: #----IF A CATEGORY HAS ONLY A SINGLE RECORD IN ENTIRE DATASET\n",
    "            counts[key] = 1\n",
    "    # ------------------------------------------------------------ STEP-3 ENDS HERE\n",
    "    \n",
    "    #print(\"BOW will have the category counts = \",counts)\n",
    "    train = pd.DataFrame(columns = df.columns)\n",
    "    test = pd.DataFrame(columns = df.columns)\n",
    "    to_drop = [] # ------------------------------------------------------------ INSTANTIATING FOR STEP-5\n",
    "    \n",
    "    # ----------------------------------------------------------- STEP-4 STARTS HERE\n",
    "    for i in range(len(df)):\n",
    "        s = len(train)\n",
    "        cat = df.loc[i,'cat']\n",
    "        if counts[cat]!=0:\n",
    "            counts[cat] = counts[cat]-1\n",
    "            train.loc[s,:] = df.loc[i,:]\n",
    "            to_drop.append(i)\n",
    "    # ------------------------------------------------------------ STEP-4 ENDS HERE\n",
    "    \n",
    "    test = df.drop(index=to_drop) # --------------------------------------------------- STEP-5\n",
    "    test = test.reset_index(drop=True)\n",
    "    return train,test # ------------------------------------------------------------ STEP-6\n",
    "    '''print(\"======== TRAIN SIZE: \",len(train))\n",
    "    print(train)\n",
    "    print(\"======== TEST SIZE: \",len(test))\n",
    "    print(test)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CELL #3: defining get_bow( df,cat )\n",
    "Function description in the top cell\n",
    "<br>The function does the following sequence of operations:\n",
    "<ol>\n",
    "    <li>Instantiate the bag of words with number of records = number of categories.</li>\n",
    "    <li>For each record in the training set, word tokenize the description and populate the corresponding category bag of words.</li>\n",
    "    <li>Return the bags of words.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bow(df,cat):\n",
    "    bow = pd.DataFrame(columns=['cat','tokens'])\n",
    "    bow['cat'] = cat # ------------------------------------------------------------ STEP-1\n",
    "    for i in range(len(bow)):\n",
    "        bow.loc[i,'tokens'] = []\n",
    "    \n",
    "    # ------------------------------------------------------------ STEP-2 STARTS HERE\n",
    "    for i in range(len(df)):\n",
    "        words = df.loc[i,'custom'].split() #------------- change to preprocessed column name as needed !!!!!!!\n",
    "        #print(words)\n",
    "        for j in range(len(bow)):\n",
    "            if bow.loc[j,'cat'] == df.loc[i,'cat']:\n",
    "                bow.loc[j,'tokens'].extend(words)\n",
    "                break\n",
    "    # ------------------------------------------------------------ STEP-2 ENDS HERE\n",
    "    \n",
    "    for i in range(len(bow)):\n",
    "        bow.loc[i,'tokens'] = list(set(bow.loc[i,'tokens'])) # REMOVE DULPICATE WORDS FROM EACH BAG\n",
    "        \n",
    "    print(\"--------------- BAG OF WORDS PREPARED!! ----------------\")\n",
    "    #print(bow)\n",
    "    return bow # ------------------------------------------------------------ STEP-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CELL #4: defining get_results( bow,test ) & predict_categories( bow,test )\n",
    "Function descriptions in the top cell\n",
    "<br>\n",
    "#### The function get_results( bow,test ) does the following sequence of operations:\n",
    "<ol>\n",
    "    <li>For each record in the test set, compute the fraction of its description words (stored in 'percent' variable) present in each bag of words. Store these values as a single list.</li>\n",
    "    <li>Return these list of values.</li>\n",
    "</ol>\n",
    "<b>The function predict_categories( bow,test ) does the following sequence of operations:</b>\n",
    "<br>Prepare the result dataset with each record depicting the item name and the list of fraction values corresponding to the number of words in each bag of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(bow,test):\n",
    "    percent=pd.DataFrame(columns=['name','percents','label'])\n",
    "    p=[]\n",
    "    \n",
    "    # ------------------------------------------------------------ STEP-1 STARTS HERE\n",
    "    for i in range(len(test)): # for each record in test set\n",
    "        #print(\"------ TEST ELEMENT: \",i+1)\n",
    "        words = test.loc[i,'custom'].split() #------------- change to preprocessed column name as needed !!!!\n",
    "        size = len(words)\n",
    "        count = 0\n",
    "        #print(\"--------------------Number of bags of words = \",len(bow))\n",
    "        for j in range(len(bow)): # for each bag of words\n",
    "            BOW = bow.loc[j,'tokens']\n",
    "            for k in range(len(words)):\n",
    "                if words[k] in BOW:\n",
    "                    count = count+1 \n",
    "            p.append(count/size) #computing the fraction value for each bag of word\n",
    "            count = 0\n",
    "        percent.loc[i,'name'] = test.loc[i,'name']\n",
    "        percent.loc[i,'percents'] = p\n",
    "        #print(\"---------------------------\",len(p))\n",
    "        p=[]\n",
    "    # ------------------------------------------------------------ STEP-1 ENDS HERE\n",
    "    \n",
    "    #print(percent)\n",
    "    #percent.to_csv(\"bow_r.csv\",index=False)\n",
    "    \n",
    "    return percent['percents'] # ------------------------------------------------------------ STEP-2\n",
    "\n",
    "'''-------------------------------------------------------------------------------------------'''\n",
    "            \n",
    "def predict_categories(bow,test):\n",
    "    \n",
    "    # ------- STEP TO PREPARE THE DATAFRAME FOR SUBSEQUENT TASKS IN THE DRIVER FUNCTION\n",
    "    \n",
    "    results = pd.DataFrame(columns=['name','actual','values'])\n",
    "    results['name'] = test['name']\n",
    "    results['actual'] = test['cat']\n",
    "    #print(\"=================\",len(np.unique(results['actual'])))\n",
    "    results['values'] = get_results(bow,test)\n",
    "    return results\n",
    "\n",
    "    #------------------------------------------------------ STEP ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CELL #5: defining bow_model( data,cat )\n",
    "<br>The driver function for the Bag of Words model\n",
    "<br>Function description in the top cell.\n",
    "<br>The function does the following sequence of operations:\n",
    "<ol>\n",
    "    <li>Define the size of the training set to be used for creating the bag of words.</li>\n",
    "    <li>Shuffle the dataset to avoid any sequential patterns from creeping into the training set.</li>\n",
    "    <li>Create train and test sets</li>\n",
    "    <li>Create the bags of words</li>\n",
    "    <li>Predict the categories for the records in the test set</li>\n",
    "    <li>For each record in the test set, choose the category with the highest fraction score aas its predicted category</li>\n",
    "    <li>Store the results in the CSV file 'bow_results.csv'</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_model(data,cat):\n",
    "    \n",
    "    print(\"--------------------- BAG OF WORDS APPROACH STARTS......\")\n",
    "    \n",
    "    print(\"Original number of records = \",len(data))\n",
    "    \n",
    "    TRAIN_SIZE = 0.90 # ------------------------------------------------------------ STEP-1\n",
    "    \n",
    "    print(\"Training/BOW preparation set will be of size approx. = \",math.floor(TRAIN_SIZE * len(data)))\n",
    "    print(\"Test set will be of size approx. = \",math.floor((1-TRAIN_SIZE) * len(data)))\n",
    "    \n",
    "    data = data.sample(frac=1,random_state=40).reset_index(drop=True) # ------------ STEP-2\n",
    "    \n",
    "    train,test = get_dataframes(data,TRAIN_SIZE) # --------------------------------- STEP-3\n",
    "    \n",
    "    bow = get_bow(train,cat) # ----------------------------------------------------- STEP-4\n",
    "    \n",
    "    print(\"PREDICTING FOR TEST SET...........\")\n",
    "    \n",
    "    r = predict_categories(bow,test) # --------------------------------------------- STEP-5\n",
    "    labels=[]\n",
    "    \n",
    "    # ------------------------------------------------------------ STEP-6 STARTS HERE\n",
    "    \n",
    "    for i in range(len(r)):\n",
    "        #print(\"------ PREDICTING FOR TEST ELEMENT: \",i+1)\n",
    "        max_value = max(r.loc[i,'values'])\n",
    "        #print(\"Max value: \",max_value)\n",
    "        index = r.loc[i,'values'].index(max_value)\n",
    "        #print(\"Label will be = \",cat[index],\" (\",index,\")\")\n",
    "        #print(\"\")\n",
    "        labels.append(cat[index])\n",
    "        \n",
    "    # ------------------------------------------------------------ STEP-6 ENDS HERE\n",
    "    \n",
    "    r['predicted'] = labels\n",
    "    r.to_csv(\"output_files/bow_results.csv\",index=False) # -------------------------------------- STEP-7\n",
    "    print(\"--------------------- BAG OF WORDS APPROACH ENDS......\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
