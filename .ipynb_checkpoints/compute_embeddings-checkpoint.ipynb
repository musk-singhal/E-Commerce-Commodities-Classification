{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>compute_embeddings.ipynb</font>\n",
    "\n",
    "<br><b>Filename: compute_embeddings.ipynb</b> ---> <font color='purple'>defines the implementation pipeline for computing word embeddings for any given input text. The approach utilizes the pre-trained 50-dimensional vectors obtained using Wikipedia corpus. The file comprises of 6B tokens.</font>\n",
    "<hr/>\n",
    "This notebook specifies the following functions: ( the sequence of description is same as the sequence of their definition in the notebook cells below )\n",
    "<ol>\n",
    "    <li><b>glove_embedding( cat ): </b> Given the list of strings ( can be keywords, phrases or complete sentences ), this function returns the corresponding feature representation.</li>\n",
    "    <ul>\n",
    "        <li>For single word inputs, the function simply looks up for the word in the vector list.</li>\n",
    "        <li>For any input with >= 2 words, it computes their separate embeddings and aggregates them (average) to obtain a single n-dimensional (n=50 in this case) vector for the entire input.</li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    <li><b>embedding_model( cat ):</b> The driver function for computing feature representation for given input.</li>\n",
    "</ol>\n",
    "\n",
    "<img src='images/glove.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CELL #1: importing required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import nltk\n",
    "from scipy import spatial\n",
    "#from sklearn.manifold import TSNE\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CELL #2: defining glove_embedding( cat ):\n",
    "<br>Function description in the top cell\n",
    "<br>This function does the following sequence of operations:\n",
    "<ol>\n",
    "    <li>Import the pre-trained word vectors text file and convert it into a dictionary.</li>\n",
    "    <li>Create a dataframe to store the string and its corresponding embedding.</li>\n",
    "    <li>For each input string:</li>\n",
    "    <ol>\n",
    "        <li>Remove unnecessary spaces from the string.</li>\n",
    "        <li>Word tokenize the string</li>\n",
    "        <li>If a single word in the string, simply look up for the word in the vector file</li>\n",
    "        <li>If this single word is not in the vector file, replace the word with none.</li>\n",
    "        <li>If more than one word in the string, obtain embedding for each individual word and average them.</li>\n",
    "        <li>If any of these words is not present in the vector file, ignore the word.</li>\n",
    "        <li>Update the dataframe with the embedding for the string.</li>\n",
    "    </ol>\n",
    "    <li>Return these computed results</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove_embedding(cat):\n",
    "    \n",
    "    #---------------------------------------------------------------------- STEP-1 STARTS HERE\n",
    "    \n",
    "    embeddings_dict={}\n",
    "    with open(\"pre_trained_vectors/glove.6B.50d.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:],\"float32\")\n",
    "            embeddings_dict[word] = vector\n",
    "            \n",
    "    #---------------------------------------------------------------------- STEP-1 ENDS HERE\n",
    "    \n",
    "    cat_embeddings = pd.DataFrame(columns=['word','embedding'])  #--------- STEP-2\n",
    "    \n",
    "    #---------------------------------------------------------------------- STEP-3 STARTS HERE\n",
    "    \n",
    "    for i in range(len(cat)):\n",
    "        #print(\"-------------- Computing embedding for: \",cat[i])\n",
    "        #print(\"Text No: \",i+1)\n",
    "        cat[i] = re.sub(' +',' ',cat[i])  #-------------------------------- 3 A)\n",
    "        #cat[i] = cat[i].replace(\"  \",\" \")\n",
    "        s = len(cat_embeddings)\n",
    "        cat_embeddings.loc[s,'word'] = cat[i] \n",
    "        '''if i ==5685:\n",
    "            print(\"----\",cat[i].split())'''\n",
    "            #embeddings_dict[cat[i]]\n",
    "        if len(cat[i].split())==1: #---------------------------- 3 B) , C)\n",
    "            try:\n",
    "                cat_embeddings.loc[s,'embedding'] = embeddings_dict[(cat[i].split())[0]]\n",
    "            except KeyError as ke: #---------------------------- 3 D)\n",
    "                #print(\"WORD NOT FOUND: \",words[j])\n",
    "                cat_embeddings.loc[s,'word'] = 'none'\n",
    "                cat_embeddings.loc[s,'embedding'] = embeddings_dict['none']\n",
    "                #print(\"!!!!!!!!!     \",i,\"    !!!!!!!!!!\")\n",
    "                pass\n",
    "        else: #---------------------------- 3 B) , E)\n",
    "            words = cat[i].split(\" \")\n",
    "            words_embed=[]\n",
    "            for j in range(len(words)):\n",
    "                try:\n",
    "                    words_embed.append(embeddings_dict[words[j]])\n",
    "                except KeyError as ke: #---------------------------- 3 F)\n",
    "                    #print(\"WORD NOT FOUND: \",words[j])\n",
    "                    pass\n",
    "            cat_embeddings.loc[s,'embedding'] = np.mean(words_embed,axis=0) #----------- 3 G)\n",
    "            \n",
    "    #---------------------------------------------------------------------- STEP-3 STARTS HERE\n",
    "    \n",
    "    cat_embeddings.to_csv(\"output_files/vectors_for_svm.csv\")\n",
    "    return cat_embeddings #---------------------------- STEP-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CELL #3: defining embedding_model( cat ):\n",
    "<br>Driver function for computing feature representations for given list of strings.\n",
    "<br>Function description in the top cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_model(cat):\n",
    "    print(\"------------------ COMPUTING FEATURE REPRESENTATIONS........\")\n",
    "    g = glove_embedding(cat)\n",
    "    print(\"------------------ REPRESENTATIONS SUCCESSFULLY COMPUTED AND STORED!\")\n",
    "    return g"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
